{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a6486ed2-6f11-4e00-a0be-0316e4ed61d5",
   "metadata": {},
   "source": [
    "Copyright Ann Arbor Algorithms Inc. 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7f1eb0-25a2-4442-a85f-79ce7352f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/abetlen/llama-cpp-python\n",
    "\n",
    "#!CMAKE_ARGS=\"-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS\" pip3 install llama-cpp-python\n",
    "#!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip3 install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43b29be-61d6-411d-b963-4c3e6b655494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-5894517a-385e-4fbd-812d-c2d8edda100b', 'object': 'text_completion', 'created': 1723057110, 'model': '../models/gguf/Meta-Llama-3-8B-Instruct.Q4_0.gguf', 'choices': [{'text': 'Q: Name the planets in the solar system? A: 1. Mercury, 2. Venus, 3. Earth, 4. Mars, 5. Jupiter, 6. Saturn, 7.', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 32, 'total_tokens': 46}}\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# https://huggingface.co/chatpdflocal/llama3.1-8b-gguf/tree/main\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=\"../models/gguf/Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "      verbose=False \n",
    "      # n_gpu_layers=-1, # Uncomment to use GPU acceleration\n",
    "      # seed=1337, # Uncomment to set a specific seed\n",
    "      # n_ctx=2048, # Uncomment to increase the context window\n",
    ")\n",
    "output = llm(\n",
    "      \"Q: Name the planets in the solar system? A: \", # Prompt\n",
    "      max_tokens=32, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "      stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      echo=True # Echo the prompt back in the output\n",
    ") # Generate a completion, can also call create_completion\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
